{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio.v3 as iio\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d.art3d import Poly3DCollection\n",
    "import numpy as np\n",
    "import open3d as o3d\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import segment\n",
    "from scipy import ndimage as ndi\n",
    "from skimage import color, feature, filters, morphology, measure, segmentation, util\n",
    "from stl import mesh\n",
    "import sys\n",
    "import yaml\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read YAML input file\n",
    "yaml_file = Path(r'C:\\Users\\gusb\\Research\\PSAAP\\segmentflow-input-gus.yml')\n",
    "stream = open(yaml_file, 'r')\n",
    "UI = yaml.load(stream,Loader=yaml.FullLoader)   # User Input\n",
    "stream.close()\n",
    "# Process User Input\n",
    "ui_ct_img_dir           = UI['Files']['CT Scan Dir']\n",
    "ui_stl_dir_location     = UI['Files']['STL Dir']\n",
    "ui_output_filename_base = UI['Files']['STL Prefix']\n",
    "ui_stl_overwrite        = UI['Files']['Overwrite Existing STL Files']\n",
    "ui_single_particle_iso  = UI['Files']['Particle ID']\n",
    "ui_suppress_save_msg    = UI['Files']['Suppress Save Messages']\n",
    "ui_file_suffix          = UI['Load']['File Suffix']\n",
    "ui_slice_crop           = UI['Load']['Slice Crop']\n",
    "ui_row_crop             = UI['Load']['Row Crop']             \n",
    "ui_col_crop             = UI['Load']['Col Crop']\n",
    "ui_use_median_filter    = UI['Preprocess']['Apply Median Filter']\n",
    "ui_rescale_range        = UI['Preprocess']['Rescale Intensity Range']\n",
    "ui_n_otsu_classes       = UI['Binarize']['Number of Otsu Classes']\n",
    "ui_n_selected_classes   = UI['Binarize']['Number of Classes to Select']\n",
    "ui_use_int_dist_map     = UI['Segment']['Use Integer Distance Map']\n",
    "ui_min_peak_distance    = UI['Segment']['Min Peak Distance']\n",
    "ui_exclude_borders      = UI['Segment']['Exclude Border Particles']\n",
    "ui_n_erosions           = UI['STL']['Number of Pre-Surface Meshing Erosions']    \n",
    "ui_median_filter        = UI['STL']['Smooth Voxels with Median Filtering']\n",
    "ui_spatial_res          = UI['STL']['Pixel-to-Length Ratio']\n",
    "ui_voxel_step_size      = UI['STL']['Marching Cubes Voxel Step Size']    \n",
    "ui_mesh_smooth_n_iters  = UI['STL']['Number of Smoothing Iterations']  \n",
    "ui_mesh_simplify_n_tris = UI['STL']['Target number of Triangles/Faces']\n",
    "ui_mesh_simplify_factor = UI['STL']['Simplification factor Per Iteration']\n",
    "ui_show_segment_fig     = UI['Plot']['Show Segmentation Figure']\n",
    "ui_n_imgs               = UI['Plot']['Number of Images']\n",
    "ui_plot_maxima          = UI['Plot']['Plot Maxima']\n",
    "ui_show_label_fig       = UI['Plot']['Show Particle Labels Figure']\n",
    "ui_label_idx            = UI['Plot']['Particle Label Image Index']\n",
    "ui_show_stl_fig         = UI['Plot']['Show Random STL Figure']\n",
    "# Load images\n",
    "print('Loading images...')\n",
    "imgs = segment.load_images(\n",
    "    ui_ct_img_dir,\n",
    "    slice_crop=ui_slice_crop,\n",
    "    row_crop=ui_row_crop,\n",
    "    col_crop=ui_col_crop,\n",
    "    convert_to_float=True,\n",
    "    file_suffix=ui_file_suffix\n",
    ")\n",
    "print('--> Images loaded as 3D array: ', imgs.shape)\n",
    "print('--> Size of array (GB): ', imgs.nbytes / 1E9)\n",
    "# Plot images\n",
    "fig, axes = segment.plot_imgs(imgs, n_imgs=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add preprocessing step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Median filter followed by intensity rescale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Preprocessing images...')\n",
    "imgs_pre = segment.preprocess(\n",
    "    imgs, median_filter=True, rescale_intensity_range=ui_rescale_range\n",
    ")\n",
    "print('--> Preprocessing complete')\n",
    "print('--> Size of array (GB): ', imgs_pre.nbytes / 1E9)\n",
    "# Plot preprocessed images\n",
    "fig, axes = segment.plot_imgs(imgs_pre, n_imgs=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Binarizing images...')\n",
    "# Borders must be excluded after seg. to avoid exclusion of connected regions\n",
    "imgs_binarized, thresh_vals = segment.binarize_multiotsu(\n",
    "    imgs_pre, \n",
    "    n_otsu_classes=ui_n_otsu_classes, \n",
    "    n_selected_thresholds=ui_n_selected_classes, \n",
    "    exclude_borders=False, \n",
    ")\n",
    "print('--> Binarization complete')\n",
    "print('--> Size of array (GB): ', imgs_binarized.nbytes / 1E9)\n",
    "# Plot binarized images\n",
    "fig, axes = segment.plot_imgs(imgs_binarized, n_imgs=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segment the Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Segmenting images...')\n",
    "segment_dict = segment.watershed_segment(\n",
    "    imgs_binarized, min_peak_distance=ui_min_peak_distance, \n",
    "    use_int_dist_map=ui_use_int_dist_map, return_dict=True\n",
    ")\n",
    "print('--> Segmentation complete')\n",
    "# How Many Particles Were Segmented?\n",
    "n_particles = np.max(segment_dict['integer-labels'])\n",
    "n_particles_digits = len(str(n_particles))\n",
    "print('--> Total number of particles segmented: ' + str(n_particles))\n",
    "# Plot segmentation results\n",
    "fig, axes = segment.plot_segment_steps(imgs, imgs_pre, imgs_binarized, segment_dict)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exclude border particles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ui_exclude_borders:\n",
    "    # How Many Particles Were Segmented?\n",
    "    n_particles = np.max(segment_dict['integer-labels'])\n",
    "    n_particles_digits = len(str(n_particles))\n",
    "    print('--> Number of particles before border exclusion: ', str(n_particles))\n",
    "    print()\n",
    "    print('Excluding border particles...')\n",
    "    segment_dict['integer-labels'] = segmentation.clear_border(\n",
    "        segment_dict['integer-labels']\n",
    "    )\n",
    "regions = measure.regionprops(segment_dict['integer-labels'])\n",
    "n_particles_noborder = len(regions)\n",
    "print('--> Number of particles: ', str(n_particles_noborder))\n",
    "fig, axes = segment.plot_segment_steps(imgs, imgs_pre, imgs_binarized, segment_dict)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Surface meshing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_surface_mesh(\n",
    "        imgs, slice_crop, row_crop, col_crop,\n",
    "        min_slice, min_row, min_col, spatial_res=1, voxel_step_size=1\n",
    "):\n",
    "    verts, faces, normals, values = measure.marching_cubes(\n",
    "        imgs, step_size=voxel_step_size,\n",
    "        allow_degenerate=False\n",
    "    )\n",
    "    # Convert vertices (verts) and faces to numpy-stl format for saving:\n",
    "    vertice_count = faces.shape[0]\n",
    "    stl_mesh = mesh.Mesh(\n",
    "        np.zeros(vertice_count, dtype=mesh.Mesh.dtype),\n",
    "        remove_empty_areas=False\n",
    "    )\n",
    "    for i, face in enumerate(faces):\n",
    "        for j in range(3):\n",
    "            stl_mesh.vectors[i][j] = verts[face[j], :]\n",
    "    # Calculate offsets for STL coordinates\n",
    "    if col_crop is not None:\n",
    "        x_offset = col_crop[0]\n",
    "    else: \n",
    "        x_offset = 0\n",
    "    if row_crop is not None:\n",
    "        y_offset = row_crop[0]\n",
    "    else: \n",
    "        y_offset = 0\n",
    "    if slice_crop is not None:\n",
    "        z_offset = slice_crop[0]\n",
    "    else:\n",
    "        z_offset = 0\n",
    "    # Add offset related to particle location. Subtracted by one to \n",
    "    # account for voxel padding on front end of each dimension.\n",
    "    x_offset += min_col - 1\n",
    "    y_offset += min_row - 1\n",
    "    z_offset += min_slice - 1\n",
    "    # Apply offsets to (x, y, z) coordinates of mesh\n",
    "    stl_mesh.x += x_offset\n",
    "    stl_mesh.y += y_offset\n",
    "    stl_mesh.z += z_offset\n",
    "    # stl_mesh.vectors are the position vectors. Multiplying by the \n",
    "    # spatial resolution of the scan makes these vectors physical.\n",
    "    stl_mesh.vectors *= spatial_res\n",
    "    return stl_mesh, verts, faces, normals, values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterate through regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_regions_as_stl_files(\n",
    "    regions,\n",
    "    stl_dir_location,\n",
    "    output_filename_base,\n",
    "    n_particles_digits,\n",
    "    suppress_save_msg=True,\n",
    "    slice_crop=None,\n",
    "    row_crop=None,\n",
    "    col_crop=None,\n",
    "    stl_overwrite=False,\n",
    "    spatial_res=1,\n",
    "    n_erosions=None,\n",
    "    median_filter_voxels=True,\n",
    "    voxel_step_size=1,\n",
    "    mesh_smooth_n_iters=None, \n",
    "    mesh_simplify_n_tris=None, \n",
    "    mesh_simplify_factor=None, \n",
    "):\n",
    "    props_df = pd.DataFrame(columns=[\n",
    "        'particleID',\n",
    "        'meshed',\n",
    "        'n_voxels',\n",
    "        'n_triangles',\n",
    "        'min_slice',\n",
    "        'max_slice',\n",
    "        'min_row',\n",
    "        'max_row',\n",
    "        'min_col',\n",
    "        'max_col',\n",
    "    ])\n",
    "    for region in regions:\n",
    "        # Create save path\n",
    "        fn = (\n",
    "            f'{output_filename_base}'\n",
    "            f'_{str(region.label).zfill(n_particles_digits)}.stl'\n",
    "        )\n",
    "        stl_save_path = Path(stl_dir_location) / fn\n",
    "        # If STL can be saved, continue with process\n",
    "        if stl_save_path.exists() and not stl_overwrite:\n",
    "            raise ValueError(f'STL already exists: {stl_save_path}')\n",
    "        elif not Path(stl_dir_location).exists():\n",
    "            # Make directory if it doesn't exist\n",
    "            Path(stl_dir_location).mkdir(parents=True)\n",
    "        # Get bounding slice, row, and column\n",
    "        min_slice, min_row, min_col, max_slice, max_row, max_col = region.bbox\n",
    "        # If particle has less than 2 voxels in each dim, do not mesh surface\n",
    "        # (marching cubes limitation)\n",
    "        props = {}\n",
    "        props['particleID'] = region.label\n",
    "        props['n_voxels']   = region.area\n",
    "        props['centroid']   = region.centroid\n",
    "        props['min_slice']  = min_slice\n",
    "        props['max_slice']  = max_slice\n",
    "        props['min_row']    = min_row\n",
    "        props['max_row']    = max_row\n",
    "        props['min_col']    = min_col\n",
    "        props['max_col']    = max_col\n",
    "        if (\n",
    "            max_slice - min_slice <= 2 + 2*n_erosions\n",
    "            and max_row - min_row <= 2 + 2*n_erosions\n",
    "            and max_col - min_col <= 2 + 2*n_erosions\n",
    "        ):\n",
    "            props['meshed'] = False\n",
    "            print(\n",
    "                f'Surface mesh not created for particle {region.label}: '\n",
    "                'Particle smaller than minimum width in at least one dimension.'\n",
    "            )\n",
    "        # Continue with process if particle has at least 2 voxels in each dim\n",
    "        else:\n",
    "            # Isolate Individual Particles\n",
    "            imgs_particle = region.image\n",
    "            imgs_particle_padded = np.pad(imgs_particle, 1)\n",
    "            # Insert region inside padding\n",
    "            imgs_particle_padded[1:-1, 1:-1, 1:-1] = imgs_particle\n",
    "            if n_erosions is not None and n_erosions > 0:\n",
    "                for _ in range(n_erosions):\n",
    "                    imgs_particle_padded = morphology.binary_erosion(\n",
    "                        imgs_particle_padded\n",
    "                    )\n",
    "                particle_labeled = measure.label(\n",
    "                    imgs_particle_padded, connectivity=1\n",
    "                )\n",
    "                particle_regions = measure.regionprops(particle_labeled)\n",
    "                if len(particle_regions) > 1:\n",
    "                    # Sort particle regions by area with largest first\n",
    "                    particle_regions = sorted(\n",
    "                        particle_regions, key=lambda r: r.area, reverse=True\n",
    "                    )\n",
    "                    # Clear non-zero voxels from imgs_particle_padded\n",
    "                    imgs_particle_padded = np.zeros_like(\n",
    "                        imgs_particle_padded, dtype=np.uint8\n",
    "                    )\n",
    "                    # Add non-zero voxels back for voxels belonging to largest \n",
    "                    # particle present (particle_regions[0])\n",
    "                    imgs_particle_padded[\n",
    "                        particle_labeled == particle_regions[0].label\n",
    "                    ] = 255  # (255 is max for 8-bit/np.uint8 image)\n",
    "            if median_filter_voxels:\n",
    "                # Median filter used to smooth particle in image/voxel form\n",
    "                imgs_particle_padded = filters.median(imgs_particle_padded)\n",
    "            # Perform marching cubes surface meshing when array has values > 0\n",
    "            try:\n",
    "                stl_mesh, vertices, faces, normals, vals = create_surface_mesh(\n",
    "                    imgs_particle_padded, slice_crop, row_crop, col_crop, \n",
    "                    min_slice, min_row, min_col, spatial_res=spatial_res, \n",
    "                    voxel_step_size=voxel_step_size\n",
    "                )\n",
    "                stl_mesh.save(stl_save_path)\n",
    "                stl_mesh, mesh_props = segment.postprocess_mesh(\n",
    "                    stl_save_path, smooth_iter=mesh_smooth_n_iters, \n",
    "                    simplify_n_tris=mesh_simplify_n_tris, \n",
    "                    iterative_simplify_factor=mesh_simplify_factor, \n",
    "                    recursive_simplify=False, resave_mesh=True\n",
    "                )\n",
    "                props['meshed'] = True\n",
    "                props = {**props, **mesh_props}\n",
    "                if not suppress_save_msg:\n",
    "                    print(f'STL saved: {stl_save_path}')\n",
    "            except RuntimeError as error:\n",
    "                props['meshed'] = False\n",
    "                print(\n",
    "                    f'Surface mesh not created for particle {region.label}:',\n",
    "                    error\n",
    "                )\n",
    "        props_df = pd.concat(\n",
    "            [props_df, pd.DataFrame.from_records([props])], ignore_index=True\n",
    "        )\n",
    "    csv_fn = (f'{output_filename_base}_properties.csv')\n",
    "    csv_save_path = Path(stl_dir_location) / csv_fn\n",
    "    props_df.to_csv(csv_save_path, index=False)\n",
    "    # Count number of meshed particles\n",
    "    n_saved = len(np.argwhere(props_df['meshed'].to_numpy()))\n",
    "    print(f'{n_saved} STL file(s) saved: {stl_dir_location}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_regions_as_stl_files(\n",
    "    regions,\n",
    "    ui_stl_dir_location,\n",
    "    ui_output_filename_base,\n",
    "    n_particles_digits,\n",
    "    suppress_save_msg=ui_suppress_save_msg,\n",
    "    slice_crop=ui_slice_crop,\n",
    "    row_crop=ui_row_crop,\n",
    "    col_crop=ui_col_crop,\n",
    "    stl_overwrite=ui_stl_overwrite,\n",
    "    spatial_res=ui_spatial_res,\n",
    "    n_erosions=ui_n_erosions,\n",
    "    median_filter_voxels=ui_median_filter,\n",
    "    voxel_step_size=ui_voxel_step_size,\n",
    "    mesh_smooth_n_iters=ui_mesh_smooth_n_iters, \n",
    "    mesh_simplify_n_tris=ui_mesh_simplify_n_tris, \n",
    "    mesh_simplify_factor=ui_mesh_simplify_factor, \n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "c3ea4ac3b0a981222cd6c1b31ef210f70ea1aaeaaf9d024a28a9ae05259f6363"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
